<article class="tutorial">
  <h1>Knowledge &amp; RAG: Chunking + Retrieval</h1>
  <p class="lede">RAG is a pipeline: you chunk documents, embed them, retrieve relevant pieces, and then answer. Most failures are pipeline failures — not “the model is dumb”.</p>

  <h2>Prereqs</h2>
  <ul>
    <li><a href="?t=ai-101-what-models-do">AI 101: What Models Do</a></li>
  </ul>

  <h2>Core concepts</h2>
  <ul>
    <li><strong>Chunking:</strong> Split docs into retrievable units with headers that carry context.</li>
    <li><strong>Retrieval:</strong> Select the few chunks that actually support the answer.</li>
    <li><strong>Grounding:</strong> Responses should cite retrieved text; bad chunks cause bad answers.</li>
  </ul>

  <h2>Worked example: from doc to chunk</h2>
  <ol>
    <li>Take a policy PDF with sections and dates.</li>
    <li>Chunk by headings; keep metadata: title, section heading, page, date.</li>
    <li>Write two target questions (e.g., "What is the PTO cap?" and "Who approves exceptions?").</li>
    <li>Verify that each question has at least one chunk that clearly answers it.</li>
  </ol>

  <h2>Mini build: a first chunking plan</h2>
  <ol>
    <li>Pick one document type (policies, docs, meeting notes).</li>
    <li>Choose chunk size (by heading or ~400–800 tokens) and metadata (title, section, date, source).</li>
    <li>Define two question types you must answer: fact lookup and multi-sentence explanation.</li>
    <li>Spot-check 3 random chunks to confirm they include enough context without being too long.</li>
  </ol>

  <section class="practice-lab">
    <h2>Practice Lab</h2>
    <p><strong>Task:</strong> Design a chunking plan for one document set.</p>
    <p><strong>Do:</strong> Choose a doc type. Decide chunk size and the metadata you will keep (title, section, date). Write two questions your system must answer.</p>
    <p><strong>Success criteria:</strong></p>
    <ul>
      <li>Your plan includes metadata that improves retrieval (at least title and section).</li>
      <li>You can name two question types the system should answer and which chunks cover them.</li>
      <li>You list two ways chunking can fail (too small, too big, missing headers).</li>
    </ul>
    <p><strong>Verify:</strong> Manually pick three questions and confirm you can find supporting text in your chosen chunks.</p>
  </section>

  <h2>Practice prompts</h2>
  <ul>
    <li>Write a chunking plan for HR policies and include metadata fields; ask the model to predict two failure modes of the plan.</li>
    <li>Design retrieval for API docs: request top-3 chunks and have the model label which chunk answers which part of the question.</li>
    <li>For meeting transcripts, ask the model to cite chunk IDs for action items; include a rule for what to do when no chunk supports the answer.</li>
  </ul>
  <p><strong>Learn more:</strong> <a href="https://python.langchain.com/docs/use_cases/question_answering/">LangChain QA guide</a> for retrieval patterns and chunking tips.</p>

  <h2>Recap</h2>
  <ul>
    <li>Chunk with structure and metadata so retrieval stays grounded.</li>
    <li>Design around the questions you need to answer, not generic embeddings.</li>
    <li>Manually verify early that every critical question has a supporting chunk.</li>
  </ul>

  <h2>Next</h2>
  <p><a href="?t=rag-hands-on-chunking-and-retrieval-tuning">Knowledge &amp; RAG: Hands-on Tuning</a></p>

  <h2>Related</h2>
  <ul>
    <li><a href="?t=evaluation-basics-metrics-vs-judges">Evaluation: Metrics vs Judges</a></li>
    <li><a href="?t=safety-ethics-practical-ai-use">Safety &amp; Ethics: Practical AI Use</a></li>
  </ul>
</article>
