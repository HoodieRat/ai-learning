<article class="tutorial">
  <h1>Audio AI: TTS &amp; STT Basics</h1>
  <p class="lede">Audio AI is usually a pipeline: capture → transcribe (STT) → process → synthesize (TTS). This tutorial covers what quality means and where it breaks.</p>

  <h2>Prereqs</h2>
  <ul>
    <li><a href="?t=ai-101-what-models-do">AI 101: What Models Do</a></li>
  </ul>

  <h2>Quality concepts</h2>
  <ul>
    <li><strong>WER:</strong> word error rate (but can hide important errors).</li>
    <li><strong>Diarization:</strong> who spoke when.</li>
    <li><strong>Latency:</strong> delays can matter more than accuracy in some apps.</li>
  </ul>

  <h2>Worked example: define good enough</h2>
  <ol>
    <li>Use case: meeting notes.</li>
    <li>Critical needs: speaker names correct; action items captured.</li>
    <li>Acceptable errors: minor filler words; non-critical small mistakes.</li>
    <li>Verification: spot-check names and action items in a 1–2 minute clip.</li>
  </ol>

  <h2>Mini build: your quality bar</h2>
  <ol>
    <li>Write 5 requirements (accuracy for names/numbers, latency target).</li>
    <li>Pick a 1–2 minute clip; transcribe with your chosen tool.</li>
    <li>Check the two most critical requirements manually.</li>
    <li>Decide if the tool meets “good enough” for this use; note gaps.</li>
  </ol>

  <section class="practice-lab">
    <h2>Practice Lab</h2>
    <p><strong>Task:</strong> Define “good enough” transcription for your use case.</p>
    <p><strong>Do:</strong> Write 5 requirements (e.g., names must be correct; action items must be extracted).</p>
    <p><strong>Success criteria:</strong></p>
    <ul>
      <li>You have a clear definition of what matters most.</li>
      <li>You can name 2 error types that break your workflow.</li>
      <li>You can propose a verification step to catch those errors.</li>
    </ul>
    <p><strong>Verify:</strong> Transcribe a 1–2 minute clip and manually check the 2 most important requirements.</p>
  </section>

  <h2>Practice lab: STT with faster-whisper</h2>
  <ol>
    <li>Install: <code>pip install faster-whisper==1.0.0 ffmpeg-python</code>.</li>
    <li>Use a 60–90s WAV (mono, 16 kHz). If needed, downmix: <code>ffmpeg -i input.mp3 -ar 16000 -ac 1 sample.wav</code>.</li>
    <li>Run:
      <pre><code>python -m faster_whisper.transcribe sample.wav --model medium --beam-size 5 --vad-filter</code></pre>
    </li>
    <li>Save the transcript/timestamps; mark two spots with low confidence (names/numbers).</li>
    <li>Rerun with <code>--language en --task translate</code> and compare latency + accuracy.</li>
  </ol>

  <h2>Practice lab: TTS with XTTS or Piper</h2>
  <ol>
    <li>Install XTTS: <code>pip install TTS==0.22.0</code> (or use Piper for lighter, offline-only).</li>
    <li>Generate a safety announcement:
      <pre><code>tts --text "Please exit via the nearest marked door. Do not use elevators." \
    --model_name tts_models/multilingual/multi-dataset/xtts_v2 \
    --out_path out/announcement.wav</code></pre>
    </li>
    <li>Check pacing: measure clip length; ensure pauses between sentences. If rushed, lower speaking rate (<code>--speed 0.9</code>).</li>
  </ol>

  <h2>Practice lab: noisy vs clean</h2>
  <ol>
    <li>Transcribe a noisy clip and a clean clip with the same command.</li>
    <li>Log word error rate for names/numbers (manual spot-check is fine) and note which errors break your workflow.</li>
    <li>Prompt the model (or post-process) to flag low-confidence spans and re-listen only to those.</li>
  </ol>

  <p><strong>Learn more:</strong> <a href="https://github.com/openai/whisper#readme">Whisper README</a> and <a href="https://github.com/SYSTRAN/faster-whisper">faster-whisper</a> for usage and models.</p>

  <h2>Assets</h2>
  <ul>
    <li><a href="assets/examples/audio/README.md">Audio quickstart commands</a> (STT/TTS, downmix)</li>
  </ul>

  <h2>Start → Run → Verify checklist</h2>
  <ul>
    <li>Start: have a 60–90s mono 16 kHz WAV; install faster-whisper/XTTS.</li>
    <li>Run: transcribe once (names/numbers focus); synthesize one short TTS clip.</li>
    <li>Verify: spot-check two critical items (names/numbers); confirm pacing/pauses on TTS.</li>
  </ul>

  <h2>Recap</h2>
  <ul>
    <li>Define quality by what matters (names, numbers, actions), not just WER.</li>
    <li>Short manual checks catch the failures that metrics miss.</li>
    <li>Latency can trump accuracy for some workflows; decide up front.</li>
  </ul>

  <h2>Next</h2>
  <p><a href="?t=audio-ai-hands-on-transcribe-and-summarize">Audio AI: Hands-on Transcribe + Summarize</a></p>

  <h2>Related</h2>
  <ul>
    <li><a href="?t=evaluation-basics-metrics-vs-judges">Evaluation: Metrics vs Judges</a></li>
    <li><a href="?t=safety-ethics-practical-ai-use">Safety &amp; Ethics: Practical AI Use</a></li>
  </ul>
</article>
