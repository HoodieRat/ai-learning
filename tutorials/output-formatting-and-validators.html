<article class="tutorial">
  <h1>Output Formatting: JSON, Checklists, and Self‑Validation</h1>
  <p class="lede">Force consistent outputs using schemas, validators, and step-by-step “verify then answer” patterns.</p>

  <h2>Core concepts</h2>
  <ul>
<li>Models predict tokens, not truth; structure prompts accordingly.</li>
<li>Hallucinations happen without grounding; verification is mandatory.</li>
<li>Temperature/context settings change both creativity and drift.</li>
  </ul>

  <h2>Worked example</h2>
  <ol>
<li>Prompt for answer + assumptions + ways to be wrong.</li>
<li>Ask for verifiable claims you can check.</li>
<li>Compare structured vs unstructured outputs to see drift.</li>
  </ol>

  <h2>Mini build</h2>
  <ol>
<li>Write a verify-first prompt template.</li>
<li>Test it on two domains.</li>
<li>Capture assumptions and mismatches in notes.</li>
  </ol>

  <section class="practice-lab">
    <h2>Practice Lab</h2>
    <p><strong>Task:</strong> Prompt for answer+assumptions+ways-wrong and verify one claim.</p>
    <p><strong>Success criteria:</strong></p>
    <ul>
      <li>You capture parameters and outputs for the run.</li>
      <li>You can repeat the run and get consistent behavior.</li>
      <li>You note at least one risk or failure mode to watch.</li>
    </ul>
  </section>

  <h2>Recap</h2>
  <ul>
<li>Models predict tokens, not truth.</li>
<li>Ask for assumptions and verifications.</li>
<li>Structure reduces drift.</li>
  </ul>

  <h2>Next</h2>
  <p>Pick a related tutorial from the catalog to deepen the skill.</p>
</article>
