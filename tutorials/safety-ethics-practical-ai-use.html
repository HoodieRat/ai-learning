<article class="tutorial">
  <h1>Safety &amp; Ethics: Practical AI Use</h1>
  <p class="lede">Safety isn’t theoretical; it’s operational. This tutorial covers the everyday practices that reduce harm: data boundaries, disclosure, and verification for high-stakes outputs.</p>

  <h2>Prereqs</h2>
  <ul>
    <li><a href="?t=ai-101-what-models-do">AI 101: What Models Do</a></li>
  </ul>

  <h2>Practical rules</h2>
  <ul>
    <li><strong>Data minimization:</strong> don’t paste secrets or personal data unless you must.</li>
    <li><strong>Disclosure:</strong> label AI-assisted content when it matters.</li>
    <li><strong>Verification:</strong> treat outputs as drafts, not facts.</li>
  </ul>

  <h2>Worked example: safe drafting</h2>
  <ol>
    <li>Task: draft a customer email.</li>
    <li>Rules: no account numbers; no unreleased roadmap; disclose “AI-assisted draft.”</li>
    <li>Verification: check tone, facts, and remove any names not provided.</li>
    <li>Outcome: a templated checklist you can reuse for future drafts.</li>
  </ol>

  <h2>Mini build: your team rules</h2>
  <ol>
    <li>List 4 data types to avoid (secrets, PII, contracts, medical).</li>
    <li>Define when disclosure is required and the exact phrasing.</li>
    <li>Write a verification checklist for high-stakes outputs.</li>
    <li>Add one escalation path (who to ask when unsure).</li>
  </ol>

  <section class="practice-lab">
    <h2>Practice Lab</h2>
    <p><strong>Task:</strong> Create “safe use” rules for your work.</p>
    <p><strong>Do:</strong> Write 8–12 bullet rules for your team covering: data, IP, external sharing, and verification for critical decisions.</p>
    <p><strong>Success criteria:</strong></p>
    <ul>
      <li>The rules are specific enough to follow day-to-day.</li>
      <li>At least 3 rules are about verification (not just “be careful”).</li>
      <li>You include one escalation path (who to ask when unsure).</li>
    </ul>
    <p><strong>Verify:</strong> Apply the rules to one real task and adjust them based on what was unclear.</p>
  </section>

  <h2>Practice lab: redaction + disclosure</h2>
  <ol>
    <li>Define PII for your team (emails, phone, account IDs). Write a one-line disclosure for AI-assisted outputs.</li>
    <li>Run Presidio or a simple regex pass to redact PII before model calls; sample:
      <pre><code>python -m presidio_analyzer --text "User Jane Doe, account 123-456" --fields PERSON, US_DRIVER_LICENSE</code></pre>
    </li>
    <li>Verify redaction on a fake log that contains at least one of each PII type.</li>
  </ol>

  <h2>Practice lab: high-stakes checklist</h2>
  <ol>
    <li>Pick a high-stakes task (medical/legal/finance) and write a 6–8 item checklist: data allowed, data banned, disclosure wording, required human reviewer, required citations, and blocking conditions.</li>
    <li>Run one real example through the checklist and log what failed.</li>
  </ol>

  <h2>Practice lab: audit trail</h2>
  <ol>
    <li>Create a JSONL log schema: {timestamp, input_hash, model, prompt_version, reviewer, decision, notes}.</li>
    <li>Log two model runs (one approved, one blocked) to prove the trail works.</li>
  </ol>

  <h2>Assets</h2>
  <ul>
    <li><a href="assets/examples/safety/redteam-prompts.md">Red-team prompt starters</a></li>
    <li><a href="assets/examples/local-ai/offline-run-log.csv">Example audit log rows</a></li>
  </ul>

  <h2>Start → Run → Verify checklist</h2>
  <ul>
    <li>Start: define PII list, disclosure line, and audit log fields.</li>
    <li>Run: redaction pass on a fake log; one red-team prompt; log two runs (approved/blocked).</li>
    <li>Verify: PII removed, red-team refused, audit log entries complete.</li>
  </ul>

  <p><strong>Learn more:</strong> <a href="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf">NIST AI RMF</a> and <a href="https://github.com/microsoft/presidio">Presidio</a> for PII detection/redaction.</p>

  <h2>Recap</h2>
  <ul>
    <li>Safety is habits: minimize data, disclose when relevant, verify before use.</li>
    <li>Write rules specific enough to follow daily and add an escalation contact.</li>
    <li>Apply rules to a real task to see what is missing.</li>
  </ul>

  <h2>Next</h2>
  <p><a href="?t=safety-ethics-hands-on-policy-and-red-teaming">Safety &amp; Ethics: Hands-on Policy + Red Team</a></p>

  <h2>Related</h2>
  <ul>
    <li><a href="?t=coding-ai-pitfalls-overreliance-and-security">Coding AI: Pitfalls</a></li>
    <li><a href="?t=agentic-flows-pitfalls-infinite-loops-and-tool-misuse">Agentic Flows: Pitfalls</a></li>
  </ul>
</article>
